# Cinego

此库为minimind-v所衍生的轻量视频理解大模型。

## 使用方法

### 1.训练tokenizer（可选，你也可以用我训练好的）

```shell
python train_tokenizer.py
```

### 2.提取视频特征(可选，你也可以直接下载我提取好的特征)

```shell
python preprocess.py
```

### 3.训练预训练模型

```shell
python train_pretrain.py
```

### 4.训练SFT模型

```shell
python train_sft.py
```


## 数据集


### 由于视频数据集实在太大了，这里我的Pretrain与SFT数据集选择的均为[LLaVA-Video-178K](https://huggingface.co/datasets/lmms-lab/LLaVA-Video-178K/tree/main)中的0_30_s_academic_v0_1子集


## 效果展示（测试视频均取自训练的数据集，我将结果进行翻译了）

| 视频文件名 | 🤖️ 机器生成的描述 | 👨 人类生成的描述 | 主要差异分析 |
|----------|----------------|----------------|------------|
| **0AGCS.mp4** | 浴室场景，人物穿深蓝衬衫和黑裤，手持白色塑料袋和红白格子毯，背景有白门、小窗和木柜。人物调整衬衫、查看环境，最后站在门边。 | 门口场景，人物穿黑T恤和卡其裤，手持大格子毯，背景杂乱。人物反复调整毯子，最终将其丢地又捡起。 | 1. 场景不同（浴室 vs 门口）<br>2. 机器描述更静态，人类描述动作更连贯<br>3. 人类增加动机推测（"可能准备使用毯子"） |
| **0AMBV.mp4** | 客厅场景，人物穿蓝帽衫和牛仔裤，在木咖啡桌前操作笔记本。背景有黄窗帘、白塑料袋等物品，氛围温馨。 | 走廊场景，人物调整椅子上的毯子后离开。另一段展示房间内人物操作蓝色吸尘器，准备使用。 | 1. 场景完全不一致<br>2. 机器描述存在矛盾（如同时描述"吃饭"和"拿扫帚"）<br>3. 人类描述分两个独立片段 |
| **0AYPZ.mp4** | 木地板房间，人物穿蓝夹克坐地持小物件，背景有玻璃门和花纹桌。保持静态偶尔调整姿势。 | 明亮厨房，人物穿深色长袖烹饪，使用红锅搅拌，后喝水、洗杯子，最后继续烹饪。 | 1. 场景完全不同（起居室 vs 厨房）<br>2. 人类描述有完整行为链条<br>3. 机器描述重复环境细节 |
| **0BLSL.mp4** | 温馨厨房，人物穿红长袖在柜台备餐，操作食物盒，保持烹饪状态。 | 昏暗储藏室，人物穿深色外套操作紫色塑料袋和红色文件夹，最后抱文件站立。 | 1. 场景差异极大<br>2. 人类描述有明确物品交互逻辑<br>3. 机器描述存在语病（"start or cleaning"） |
| **0BX9N.mp4** | 昏暗浴室，人物穿黑衣操作白塑料袋和小桌子，反复调整物品。 | 明亮厨房，女人穿黑衣拆 groceries，整理食材后点燃炉灶准备烹饪。 | 1. 环境对比强烈（昏暗浴室 vs 明亮厨房）<br>2. 人类描述有明确目的性<br>3. 机器描述动作重复率高 |

### 关键结论
1. **场景准确性**：人类描述的场景细节更具体且一致，机器常出现矛盾（如0AMBV同时描述"吃饭"和"拿扫帚"）
2. **行为逻辑**：人类会补充合理动机（如"准备烹饪"），机器仅记录表面动作
3. **语言质量**：人类描述流畅，机器存在重复、语病和模糊指代（如"红白相间的物体"）
4. **多片段处理**：人类能区分不同片段（如0AMBV的走廊和吸尘器），机器会混为一谈


## 致谢

- 特别感谢 [MiniMind](https://github.com/jingyaogong/minimind-v) 项目，本项目的架构和实现大量借鉴了他们的优秀工作
- 感谢 [LLaVA-Video-178K](https://huggingface.co/datasets/lmms-lab/LLaVA-Video-178K/tree/main)数据集的提供者
